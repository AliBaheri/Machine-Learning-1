# Machine Learning (coursera - Andrew Ng)
 Octave version 3.8.0
 
 Why Octave/Matlab? It supports the vectorized implementation, while using others, e.g. python, you have to implement in the `for-loop` for a bunch of information that needs to be updated concurrently.

        Author: Tung Thanh Le
        Contact: ttungl at gmail dot com

* Week #2: Univariate / Multivariate Linear Regression.
* Week #3: Logistic Regression, and Regularized Logistic Regression.
    Note that, Regularized Logistic Regression is applied with various `lambdas` to find a good fit data and the good decision boundary. If `lambda` is too large, underfitting the data (`lambda`~100). Otherwise, if it is too small, overfitting the data (`lambda`~0).   
* Week #4: Neural Network with handwritten prediction. Use `feedforward propagation algorithm` to predict the labels of training sets. 
* Week #5: Neural Network Training with handwritten. Use `backpropagation algorithm` to predict the labels of training sets. Note that, the `backprop algorithm` is implemented after running the `feedforward propagation algorithm` to compute all the `activations` and `h_theta(x)`. 
* Week #7: Support Vector Machines (SVM). `SVM` is used to perform the classifications by building the classifiers based on the training datasets. It tends to separating the boundaries between the training datasets by finding the optimal hyperplane and maximizing the margin as large as possible.   
